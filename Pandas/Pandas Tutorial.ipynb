{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides numerous tools to work with tabular data like you'd find in spreadsheets or databases. It is widely used for data preparation, cleaning, and analysis. It can work with a wide variety of data and provides many visualization options. It is built on top of NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rand_nums'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas uses something called a dataframe. It is a \n",
    "# 2D data structure that can hold multiple data types.\n",
    "# Columns have labels.\n",
    "\n",
    "# Series are built on top of NumPy arrays. \n",
    "# Create a series by first creating a list\n",
    "list_1 = ['a', 'b', 'c', 'd']\n",
    "# I can define that I want the series indexes to be the\n",
    "# provided labels\n",
    "labels = [1, 2, 3, 4]\n",
    "ser_1 = pd.Series(data=list_1, index=labels)\n",
    "\n",
    "# You can also add a NumPy array\n",
    "arr_1 = np.array([1, 2, 3, 4])\n",
    "ser_2 = pd.Series(arr_1)\n",
    "\n",
    "# You can quickly add labels and values with a dictionary\n",
    "dict_1 = {\"f_name\": \"Derek\", \n",
    "              \"l_name\": \"Banas\", \n",
    "              \"age\": 44}\n",
    "ser_3 = pd.Series(dict_1)\n",
    "\n",
    "# Get data by label\n",
    "ser_3[\"f_name\"]\n",
    "\n",
    "# You can get the datatype\n",
    "ser_2.dtype\n",
    "\n",
    "# You can perform math operations on series\n",
    "ser_2 + ser_2\n",
    "ser_2 - ser_2\n",
    "ser_2 * ser_2\n",
    "ser_2 / ser_2\n",
    "\n",
    "# You can pass them into NumPy methods\n",
    "# See NumPy tutorial for more math methods\n",
    "np.exp(ser_2)\n",
    "\n",
    "# The difference between Series and ndarray is that operations\n",
    "# align by labels\n",
    "# Create a series from a dictionary\n",
    "ser_4 = pd.Series({4: 5, 5: 6, 6: 7, 7: 8})\n",
    "# If labels don't align you will get NaN\n",
    "ser_2 + ser_4\n",
    "\n",
    "# You can assign names to series\n",
    "ser_4 = pd.Series({8: 9, 9: 10}, name='rand_nums')\n",
    "ser_4.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are the most commonly used data structure with Pandas. They are made up of multiple series that share the same index / label. They can contain multiple data types. They can be created from dicts, series, lists or other dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "# Create random matrix 2x3 with values between 10 and 50\n",
    "arr_2 = np.random.randint(10, 50, size=(2, 3))\n",
    "\n",
    "# Create DF with data, row labels & column labels\n",
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "\n",
    "# Create a DF from multiple series in a dict\n",
    "# If series are of different lengthes extra spaces are NaN\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)\n",
    "df_2\n",
    "\n",
    "# from_dict accepts a column labels and lists\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]))\n",
    "\n",
    "# You can assign the keys as row labels and column labels separate\n",
    "# with orient='index'\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]),\n",
    "                      orient='index', columns=['one','two','three'])\n",
    "\n",
    "# Get number of rows and columns as tuple\n",
    "print(df_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing & Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D   E\n",
      "A  23  23\n",
      "B  34  49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A\n",
       "0  1.0\n",
       "1  9.0\n",
       "2  3.0\n",
       "3  4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a column\n",
    "df_1['C']\n",
    "# Get multiple columns\n",
    "df_1[['C', 'E']]\n",
    "\n",
    "# Grabb a row as a series\n",
    "df_1.loc['A']\n",
    "# Grab row by index position\n",
    "df_1.iloc[1]\n",
    "\n",
    "# Grab cell with Row & Column\n",
    "df_1.loc['A', 'C']\n",
    "# Grab multiple cells by defining rows wanted & the\n",
    "# columns from those rows\n",
    "print(df_1.loc[['A', 'B'], ['D', 'E']])\n",
    "\n",
    "# Make new column\n",
    "df_1['Total'] = df_1['C'] + df_1['D'] + df_1['E']\n",
    "df_1\n",
    "\n",
    "# You can perform multiple calculations\n",
    "df_2['mult'] = df_2['one'] * df_2['two']\n",
    "df_2\n",
    "\n",
    "# Make a new row by appending\n",
    "dict_2 = {'C': 44, 'D': 45, 'E': 46}\n",
    "new_row = pd.Series(dict_2, name='F')\n",
    "df_1 = df_1.append(new_row)\n",
    "\n",
    "# Delete column and set inplace to True which is required\n",
    "# because Pandas tries to help you not delete data\n",
    "# by accident\n",
    "df_1.drop('Total', axis=1, inplace=True)\n",
    "df_1\n",
    "# Delete a row\n",
    "df_1.drop('B', axis=0, inplace=True)\n",
    "df_1\n",
    "\n",
    "# Create a new column and make it the index\n",
    "df_1['Sex'] = ['Men', 'Women']\n",
    "df_1.set_index('Sex', inplace=True)\n",
    "\n",
    "# You can reset index values to numbers\n",
    "#df_1.reset_index(inplace=True)\n",
    "df_1\n",
    "\n",
    "# Assign can be used to create a column while leaving the\n",
    "# original DF untouched\n",
    "df_2.assign(div=df_2['one'] / df_2['two'])\n",
    "\n",
    "# You can pass in a function as well\n",
    "df_2.assign(div=lambda x: (x['one'] / x['two']))\n",
    "\n",
    "# Combine DataFrames while keeping df_3 data unless\n",
    "# there is a NaN value\n",
    "df_3 = pd.DataFrame({'A': [1., np.nan, 3., np.nan]})\n",
    "df_4 = pd.DataFrame({'A': [8., 9., 2., 4.]})\n",
    "df_3.combine_first(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "print(df_1)\n",
    "\n",
    "# You can use conditional operators to retrieve a table\n",
    "# based on the condition\n",
    "print(\"Greater than 40\\n\", df_1 > 40.0)\n",
    "\n",
    "# You can use comparison operater functions as well like\n",
    "# gt, lt, ge, le, eq, ne\n",
    "print(\"Greater than 45\\n\", df_1.gt(45.0))\n",
    "\n",
    "# You can place conditions in brackets as well\n",
    "bool_1 = df_1 >= 45.0\n",
    "df_1[bool_1]\n",
    "\n",
    "# Get bools for a column\n",
    "df_1['E'] > 40\n",
    "\n",
    "# Return a row if cell value in column matches a condition\n",
    "df_1[df_1['E']>30]\n",
    "\n",
    "# You can focus on a column based on resulting dataframe\n",
    "df_2 = df_1[df_1['E']>30]\n",
    "df_2['C']\n",
    "\n",
    "# You can stack these commands\n",
    "print(df_1[df_1['E']>20]['C'])\n",
    "print()\n",
    "\n",
    "# You can also grab multiple columns\n",
    "print(df_1[df_1['E']>20][['C', 'D']])\n",
    "print()\n",
    "\n",
    "# You can use multiple conditions\n",
    "arr_3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "df_2 = pd.DataFrame(arr_3, ['A', 'B', 'C'], ['X', 'Y', 'Z'])\n",
    "print(df_2, \"\\n\")\n",
    "# You can use or | to combine conditions as well\n",
    "df_2[(df_2['X']>3) & (df_2['X']<7)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Input / Output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can work with the following types of data : CSV, Plain Text, JSON, XML, PDF, SQL, HTML, XLSX, DOCX, ZIP, Images Hierarchical Data Format, MP3, and MP4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Read a CSV file\n",
    "# Type pd.read_ [TAB] to see the file types you can read\n",
    "cs_df = pd.read_csv('ComputerSales.csv')\n",
    "\n",
    "# Save a CSV file, but don't save the index as a column\n",
    "cs_df.to_csv('ComputerSalesBU.csv', index=False)\n",
    "\n",
    "# You can read data from Excel, but not formulas and macros\n",
    "pd.read_excel('Financial Sample.xlsx',0)\n",
    "\n",
    "# Write to Excel\n",
    "cs_df.to_excel('ComputerSales.xlsx')\n",
    "\n",
    "# Check if written\n",
    "pd.read_excel('ComputerSales.xlsx',0)\n",
    "\n",
    "# Read from MySQL Database\n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    # print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()\n",
    "    \n",
    "\n",
    "# Write to table \n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "    # Used to issue queries\n",
    "    cursor = db_connection.cursor()\n",
    "    # Query to enter new student\n",
    "    insert_stmt = \"INSERT INTO students VALUES(NULL, 'Frank', 'Silva', 'fsilva@aol.com', '666 Hell St', 'Yakima', 'WA', 98901, '792-223-8966', '1959-2-22', 'M', NOW(), 3.50)\"\n",
    "    # Execute query\n",
    "    cursor.execute(insert_stmt)\n",
    "    # Commit changes to DB\n",
    "    db_connection.commit()\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()\n",
    "\n",
    "# Just get 1 column of data \n",
    "cs_df_st = pd.read_csv('ComputerSales.csv', usecols=[\"State\"], squeeze=True)\n",
    "cs_df_st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics & Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 1st 5 rows\n",
    "cs_df.head()\n",
    "# Display last 5 rows\n",
    "cs_df.tail()\n",
    "# Get 1st 2\n",
    "cs_df[:2]\n",
    "# Get 1st through 5 with a 2 step\n",
    "cs_df[:5:2]\n",
    "\n",
    "# Get indexes\n",
    "cs_df.index.array\n",
    "# Get NumPy array\n",
    "cs_df.to_numpy()\n",
    "# Get array from series\n",
    "ser_1.array\n",
    "\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)\n",
    "\n",
    "# You can replace NaN values with 0 or anything else\n",
    "print(df_2.fillna(0))\n",
    "# Get values in row 2\n",
    "row = df_2.iloc[1]\n",
    "# Add items in row 2 to all rows including row 2\n",
    "# You can do the same with sub, mul, and div\n",
    "df_2.add(row, axis='columns')\n",
    "\n",
    "# Get column 2\n",
    "col = df_2['two']\n",
    "# Subtract from other columns\n",
    "df_2.sub(col, axis=0)\n",
    "\n",
    "# Check if empty\n",
    "df_2.empty\n",
    "\n",
    "# Transform executes a function on a dataframe\n",
    "df_5 = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "df_5.transform(lambda x: x+1)\n",
    "df_5.transform(lambda x: x**2)\n",
    "df_5.transform(lambda x: np.sqrt(x))\n",
    "# You can transform using multiple functions\n",
    "df_5.transform([lambda x: x**2, lambda x: x**3])\n",
    "# Passing a dictionary allows you to perform different calculations\n",
    "# on different columns\n",
    "df_5.transform({'A': lambda x: x**2, 'B': lambda x: x**3})\n",
    "\n",
    "# map performs a function on a series\n",
    "df_5['A'].map(lambda x: x**2)\n",
    "\n",
    "# applymap does the same on a dataframe\n",
    "df_5.applymap(lambda x: x**2)\n",
    "\n",
    "# Get unique values in column 2 of DF\n",
    "df_2['two'].unique()\n",
    "\n",
    "# Get number of uniques\n",
    "df_2['two'].nunique()\n",
    "\n",
    "# Get the number of times each value showed in column 2\n",
    "df_2['two'].value_counts()\n",
    "\n",
    "# Get column names\n",
    "df_2.columns\n",
    "\n",
    "# Get index info\n",
    "df_2.index\n",
    "\n",
    "# Return a DF that lists null values as True\n",
    "df_2.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby allows you to group rows based on a columnand perform a function\n",
    "# that combines those values (Aggregate Function)\n",
    "dict_5 = {'Store': [1,2,1,2], 'Flavor': ['Choc', 'Van', 'Straw', 'Choc'], \n",
    "         'Sales': [26, 12, 18, 22]}\n",
    "\n",
    "df_11 = pd.DataFrame(dict_5)\n",
    "\n",
    "# Group data by the store number\n",
    "by_store = df_11.groupby('Store')\n",
    "# Get mean sales by store\n",
    "by_store.mean()\n",
    "\n",
    "# Get sales total just for store 1\n",
    "by_store.sum().loc[1]\n",
    "\n",
    "# You can use multiple functions of get a bunch\n",
    "by_store.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Merge & Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can concatenate DFs in the order DFs are provided\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6]},\n",
    "                    index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],\n",
    "                     'B': [10,11,12]},\n",
    "                    index=[4,5,6])\n",
    "pd.concat([df_12, df_13])\n",
    "\n",
    "# Merge 2 DFs using their shared key column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6],\n",
    "                     'key': [1,2,3]})\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],\n",
    "                     'B': [10,11,12],\n",
    "                     'key': [1,2,3]})\n",
    "# inner merges at the intersection of keys\n",
    "pd.merge(df_12, df_13, how='inner', on='key')\n",
    "# how='left' or 'right' : Use keys from left or right frame\n",
    "# how='outer' : Use union of keys\n",
    "\n",
    "# You can join DFs with different indexes and instead of using \n",
    "# keys use a column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6]},\n",
    "                    index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'C': [7,8,9],\n",
    "                     'D': [10,11,12]},\n",
    "                    index=[1,4,5])\n",
    "df_12.join(df_13, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ice cream sales data\n",
    "ics_df = pd.read_csv('icecreamsales.csv')\n",
    "ics_df\n",
    "\n",
    "# Get total count of both columns\n",
    "ics_df.count()\n",
    "\n",
    "# skipna skips null / NaN values\n",
    "ics_df.sum(skipna=True)\n",
    "# Get mean for named column\n",
    "ics_df[\"Sales\"].mean()\n",
    "ics_df[\"Sales\"].median()\n",
    "ics_df[\"Sales\"].mode()\n",
    "ics_df[\"Sales\"].min()\n",
    "ics_df[\"Sales\"].max()\n",
    "ics_df[\"Sales\"].prod() # Product of values\n",
    "ics_df[\"Sales\"].std() # Standard deviation\n",
    "ics_df[\"Sales\"].var() # Variance\n",
    "ics_df[\"Sales\"].sem() # Standard error\n",
    "# Negative : Left long tail, Positive : Right long tail\n",
    "ics_df[\"Sales\"].skew()\n",
    "# Kurtosis : < 3 less outliers, 3 Normal Distribution,\n",
    "# > 3 more outliers\n",
    "ics_df[\"Sales\"].kurt()\n",
    "ics_df[\"Sales\"].quantile(.5)\n",
    "ics_df[\"Sales\"].cumsum()\n",
    "ics_df[\"Sales\"].cumprod()\n",
    "ics_df[\"Sales\"].cummax()\n",
    "ics_df[\"Sales\"].cummin()\n",
    "\n",
    "# Multiple stats at once\n",
    "ics_df.describe()\n",
    "\n",
    "ser_dice = pd.Series(data=[2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, \n",
    "                           6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8,\n",
    "                          8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12])\n",
    "# Count for each value in series\n",
    "ser_dice.value_counts()\n",
    "\n",
    "# You can perform calculations on multiple columns using\n",
    "# aggregate\n",
    "print(df_2)\n",
    "df_2.agg(np.mean)\n",
    "\n",
    "# You can do this with multiple functions\n",
    "df_2.agg(['mean', 'std'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over series\n",
    "ser_7 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "for col in ser_7:\n",
    "    print(col)\n",
    "    \n",
    "print()\n",
    "# Iterating over DFs\n",
    "arr_4 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_8 = pd.DataFrame(arr_4, ['B', 'C'], ['C', 'D', 'E'])\n",
    "print(df_8)\n",
    "\n",
    "# items allows you to iterate through key value pairs to make\n",
    "# calculations 1 column at a time\n",
    "for label, ser in df_8.items():\n",
    "    print(label)\n",
    "    print(ser)\n",
    "    \n",
    "print()\n",
    "# You can also iterate through rows\n",
    "for index, row in df_8.iterrows():\n",
    "    print(f\"{index}\\n{row}\")\n",
    "print()\n",
    "\n",
    "# Get a tuple that contains row data\n",
    "for row in df_8.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8\n",
    "\n",
    "# Sorting by index will return the same results if indexes\n",
    "# are in order, to reverse indexes mark ascending as False\n",
    "df_8.sort_index(ascending=False)\n",
    "\n",
    "# Sort by value for column D (Use the same function for series)\n",
    "df_8.sort_values(by='D')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Data to Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# You can pass DataFrames and Series into functions\n",
    "def get_profit_total(df):\n",
    "    prof_ser = df['Profit']\n",
    "    print(f\"Total Profit : {prof_ser.sum()}\")\n",
    "\n",
    "get_profit_total(cs_df)\n",
    "\n",
    "# Receives a DataFrame, splits the contact into new columns\n",
    "# being first and last name\n",
    "def split_name(df):\n",
    "    def get_names(full_name):\n",
    "        # Split contact at space\n",
    "        f_name, l_name = full_name.split()\n",
    "        # Create a series with first & last names in columns\n",
    "        # with those labels\n",
    "        return pd.Series(\n",
    "        (f_name, l_name),\n",
    "        index=['First Name', 'Last Name']\n",
    "        )\n",
    "    # apply() executes the function on all names in Contact column\n",
    "    names = df['Contact'].apply(get_names)\n",
    "    df[names.columns] = names\n",
    "    return df\n",
    "\n",
    "# Run function and display top 5 results\n",
    "split_name(cs_df).head()\n",
    "\n",
    "# Will assign people to different age groups based on age\n",
    "def create_age_groups(df):\n",
    "    # Must have 1 more bins than labels\n",
    "    bins = [0, 30, 50, sys.maxsize]\n",
    "    # Group labels\n",
    "    labels = ['<30', '30-50', '>50']\n",
    "    \n",
    "    # cut puts values into certain groups based on intervals\n",
    "    # The group assigned to <30 has an age between 0 and 30\n",
    "    # between 30 & 50 is assigned 30-50 and so on\n",
    "    age_group = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "    # Create new column and return new dataframe info\n",
    "    df['Age Group'] = age_group\n",
    "    return df\n",
    "\n",
    "create_age_groups(cs_df)\n",
    "\n",
    "# You can use a pipe to pass a dataframe to multiple functions\n",
    "cs_df.pipe(split_name).pipe(create_age_groups).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning, Reindexing and Renaming Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_6 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "sl_1 = ser_6[:4]\n",
    "sl_2 = ser_6[1:]\n",
    "print(sl_1)\n",
    "print(sl_2)\n",
    "# Align both series by the union of their indexes\n",
    "sl_1.align(sl_2)\n",
    "# Align by calling series\n",
    "sl_1.align(sl_2, join='left')\n",
    "# Use passed series indexes\n",
    "sl_1.align(sl_2, join='right')\n",
    "# Get where indexes intersect\n",
    "sl_1.align(sl_2, join='inner')\n",
    "\n",
    "# You can use align with DFs as well\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_6 = pd.DataFrame(arr_3, ['A', 'B'], ['C', 'D', 'E'])\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_7 = pd.DataFrame(arr_3, ['B', 'C'], ['C', 'D', 'E'])\n",
    "df_6\n",
    "df_6.align(df_7)\n",
    "\n",
    "# reindex allows you to align data by index\n",
    "ser_6.reindex(['c','b','a'])\n",
    "\n",
    "# Do the same with DFs\n",
    "df_6.reindex(['B','A'])\n",
    "\n",
    "# Drop is very similar to reindex except it receives labels\n",
    "# you don't want to include\n",
    "df_6.drop(['A'], axis=0)\n",
    "df_6.drop(['D'], axis=1)\n",
    "\n",
    "# You can rename labels\n",
    "df_6.rename(columns={'C': 'Men', 'D': 'Women', 'E': 'Pets'},\n",
    "           index={'A': 1, 'B': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level indexing allows you to store data on multiple\n",
    "# dimensions\n",
    "days = ['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2']\n",
    "meals = [1,2,3,1,2,3]\n",
    "# zip pairs the days and meals arrays \n",
    "# Then we create a list of those paired tuples\n",
    "hier_index = list(zip(days, meals))\n",
    "print(hier_index)\n",
    "# Converts list of tuples into each row and column\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "# Generate random array representing calories eaten per meal\n",
    "arr_5 = np.random.randint(500, 700, size=(6, 2))\n",
    "df_9 = pd.DataFrame(arr_5, hier_index, ['M', 'F'])\n",
    "print(df_9)\n",
    "\n",
    "# Grab the day 1 DF\n",
    "df_9.loc['Day 1']\n",
    "\n",
    "# Grab 1st row as a series\n",
    "df_9.loc['Day 1'].loc[1]\n",
    "\n",
    "# Grab calories eaten by the female on day 2 for the 2nd meal\n",
    "df_9.loc['Day 2'].loc[2]['F']\n",
    "\n",
    "# We can assign names to the Day and Meals Column\n",
    "df_9.index.names = ['Day', 'Meal']\n",
    "df_9\n",
    "\n",
    "# Get a cross section\n",
    "# This gets me the Day 2 DF\n",
    "df_9.xs('Day 2')\n",
    "\n",
    "# Get calories for the 1st meal for both days by saying what\n",
    "# meal index you want and the Meal column name\n",
    "df_9.xs(1, level='Meal')\n",
    "\n",
    "# Create a MultiIndex out of a DF using a pivot table\n",
    "dict_6 = {'A':['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2'],\n",
    "         'B': [1,2,3,1,2,3],\n",
    "         'C': ['M', 'F', 'M', 'F', 'M', 'F'],\n",
    "         'D': [1,2,3,4,5,6]}\n",
    "df_14 = pd.DataFrame(dict_6)\n",
    "# Designate the D column is the data\n",
    "# Make A & B a multilevel index\n",
    "# Define column names come from column C\n",
    "# You will have NaNs where data was missing\n",
    "df_14.pivot_table(values='D', index=['A','B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_4 = {'A': [1,2,np.nan], 'B': [4, np.nan, np.nan], 'C': [7.,8.,9.]}\n",
    "df_10 = pd.DataFrame(dict_4)\n",
    "print(df_10)\n",
    "\n",
    "# Drop missing data from DF (Drops any row with missing values)\n",
    "df_10.dropna()\n",
    "\n",
    "# Drop all columns with any missing data\n",
    "df_10.dropna(axis=1)\n",
    "\n",
    "# Drop row unless it has at least 2 non-NaN values\n",
    "df_10.dropna(thresh=2)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_10.fillna(value=0.0)\n",
    "\n",
    "# Fill A column with the mean of column\n",
    "df_10['A'].fillna(value=df_10['A'].mean())\n",
    "\n",
    "# Fill with previous value\n",
    "df_10.fillna(method='ffill')\n",
    "\n",
    "# Fill with next value (Only works if there is a next value)\n",
    "df_10.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df.head() # Get 1st 5\n",
    "print(cs_df.columns) # Get column names\n",
    "cs_df['Profit'].mean() # Average profit per item\n",
    "# Get the product with the highest profit\n",
    "cs_df[['Product ID', 'Profit']].max(axis=0).head()\n",
    "# Number of people who purchased from WV\n",
    "cs_df[cs_df['State']=='WV']['State'].count()\n",
    "# Number of purchases in 2019\n",
    "len(cs_df[cs_df['Year']==2019].index)\n",
    "# Get number of sales for each product type\n",
    "cs_df['Product ID'].value_counts()\n",
    "# Get list of customers that bought a specific product\n",
    "cs_df[cs_df['Product ID']=='M01-F0024']['Contact']\n",
    "# How many made a website purchase for a profit over $200\n",
    "cs_df[(cs_df['Lead']=='Website') & (cs_df['Profit']>150)]['Lead'].count()\n",
    "# Find out how many product profit amounts include .89 in cents\n",
    "cs_df['Profit'].apply(lambda cents: str(cents).split('.')[1]=='89').value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library usef to create advanced static, animated and\n",
    "# interactive visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Displays matplotlib plots in the Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Histograms provide an approximation of the distribution of\n",
    "# results. You create them by dividing the range of values into \n",
    "# bins or buckets. Then you count how many of the results fall\n",
    "# into each bin.\n",
    "# Rolls 2 dice 5000 times and charts the frequency and \n",
    "# a histogram\n",
    "\n",
    "# Even though the odds increase as you approach 7 and then\n",
    "# decrease again (1 way to roll a 2 / 6 ways to roll a 7)\n",
    "# over many rolls they are nearly equal.\n",
    "df_dice = pd.DataFrame(\n",
    "    np.random.randint(1,7,5000),\n",
    "    columns = ['Hist'])\n",
    "df_dice['Odds'] = df_dice['Hist'] + np.random.randint(1,7,5000)\n",
    "# Alpha decreases the opacity in the chart\n",
    "ax = df_dice.plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "# Basic plot using 1000 random values that create cumulative sums\n",
    "# over an increasing date range\n",
    "ser_5 = pd.Series(np.random.randn(1000),\n",
    "                 index=pd.date_range('11/15/2017', periods=1000))\n",
    "ser_5 = ser_5.cumsum()\n",
    "# ser_5.plot()\n",
    "\n",
    "# Display 3 random plots\n",
    "df_15 = pd.DataFrame(np.random.randn(1000, 3),\n",
    "                    index=pd.date_range('11/15/2017', periods=1000),\n",
    "                    columns=list('ABC'))\n",
    "df_15 = df_15.cumsum()\n",
    "# df_15.plot()\n",
    "\n",
    "# Make bar chart from 5 random values\n",
    "# pd.DataFrame(np.random.randn(5)).plot.bar()\n",
    "\n",
    "# Make MultiBar Charts\n",
    "vals = ['A', 'B', 'C', 'D']\n",
    "df_15 = pd.DataFrame(np.random.rand(10,4), columns=vals)\n",
    "# df_15.plot.bar()\n",
    "\n",
    "# Area plot \n",
    "# Define x range and y values\n",
    "x_rng = range(1,15)\n",
    "y_vals = [1,5,4,7,6,9,5,7,10,14,10,12,9,8]\n",
    "# Change fill color and opacity\n",
    "# plt.fill_between(x_rng, y_vals, color=\"skyblue\", alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# Area plot with multiple areas\n",
    "# pd.DataFrame(np.random.rand(10,3), columns=['A','B','C']).plot.area()\n",
    "\n",
    "# Create a scatterplot with 100 random values\n",
    "# pd.DataFrame(np.random.rand(100,2), \n",
    "#              columns=['A','B']).plot.scatter(x='A', y='B')\n",
    "\n",
    "# Multiple column scatter plots\n",
    "df_15 = pd.DataFrame(np.random.rand(50,4), columns=['A','B','C','D'])\n",
    "# ax = df_15.plot.scatter(x='A', y='B', color='DarkBlue', label='Grp 1')\n",
    "# df_15.plot.scatter(x='C', y='D', color='Orange', label='Grp 2', ax=ax)\n",
    "\n",
    "# Pie Charts with 4 random values\n",
    "# pd.Series(np.random.rand(4),\n",
    "#          index=['a','b','c','d'], \n",
    "#           name='Pie').plot.pie(figsize=(6,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
