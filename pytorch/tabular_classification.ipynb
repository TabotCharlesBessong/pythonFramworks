{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice = pd.read_csv(\"./DATA/riceClassification.csv\")\n",
    "rice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_per = rice.isna().sum() \n",
    "miss_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rice.drop(['id'],axis=1,inplace=True)\n",
    "print(rice.shape)\n",
    "rice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "HIDDEN_NEURONS = 10\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organized = rice.copy()\n",
    "\n",
    "for col in rice.columns:\n",
    "  rice[col] = rice[col]/rice[col].abs().max()\n",
    "  \n",
    "rice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(rice.iloc[:,:-1])\n",
    "Y = np.array(rice.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test,Y_test,test_size=0.5,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set is: \", X_train.shape[0], \" rows which is \", round(X_train.shape[0]/rice.shape[0],4)*100, \"%\") # Print training shape\n",
    "print(\"Validation set is: \",X_val.shape[0], \" rows which is \", round(X_val.shape[0]/rice.shape[0],4)*100, \"%\") # Print validation shape\n",
    "print(\"Testing set is: \",X_test.shape[0], \" rows which is \", round(X_test.shape[0]/rice.shape[0],4)*100, \"%\") # Print testing shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, X,Y):\n",
    "    self.X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    self.Y = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset(X_train, Y_train)\n",
    "validation_data = dataset(X_val, Y_val)\n",
    "testing_data = dataset(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dataloader = DataLoader(validation_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_dataloader = DataLoader(testing_data,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_NEURONS = 10\n",
    "\n",
    "class MyModal(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModal, self).__init__()\n",
    "    self.input_layer = nn.Linear(X.shape[1], HIDDEN_NEURONS)\n",
    "    self.fc2 = nn.Linear(HIDDEN_NEURONS, HIDDEN_NEURONS)  # Second layer\n",
    "    self.fc3 = nn.Linear(HIDDEN_NEURONS, 1)  # Third layer\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.input_layer(x)\n",
    "    x = torch.relu(self.fc2(x))  # Activation before third layer\n",
    "    x = self.sigmoid(self.fc3(x))  # Apply sigmoid to final output\n",
    "    return x\n",
    "  \n",
    "model = MyModal().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,(X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimiser = Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train_plot = []\n",
    "total_loss_validation_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_validation_plot = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  total_acc_train = 0\n",
    "  total_loss_train = 0\n",
    "  total_acc_val = 0\n",
    "  total_loss_val = 0\n",
    "  ## Training and Validation\n",
    "  for data in train_dataloader:\n",
    "\n",
    "    inputs, labels = data\n",
    "\n",
    "    prediction = model(inputs).squeeze(1)\n",
    "\n",
    "    batch_loss = criterion(prediction, labels)\n",
    "\n",
    "    total_loss_train += batch_loss.item()\n",
    "\n",
    "    acc = ((prediction).round() == labels).sum().item()\n",
    "\n",
    "    total_acc_train += acc\n",
    "\n",
    "    batch_loss.backward()\n",
    "    optimiser.step()\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "  ## Validation\n",
    "  with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "      inputs, labels = data\n",
    "\n",
    "      prediction = model(inputs).squeeze(1)\n",
    "\n",
    "      batch_loss = criterion(prediction, labels)\n",
    "\n",
    "      total_loss_val += batch_loss.item()\n",
    "\n",
    "      acc = ((prediction).round() == labels).sum().item()\n",
    "\n",
    "      total_acc_val += acc\n",
    "\n",
    "  total_loss_train_plot.append(round(total_loss_train/1000, 4))\n",
    "  total_loss_validation_plot.append(round(total_loss_val/1000, 4))\n",
    "  total_acc_train_plot.append(round(total_acc_train/(training_data.__len__())*100, 4))\n",
    "  total_acc_validation_plot.append(round(total_acc_val/(validation_data.__len__())*100, 4))\n",
    "\n",
    "  print(f'''Epoch no. {epoch + 1} Train Loss: {total_loss_train/1000:.4f} Train Accuracy: {(total_acc_train/(training_data.__len__())*100):.4f} Validation Loss: {total_loss_val/1000:.4f} Validation Accuracy: {(total_acc_val/(validation_data.__len__())*100):.4f}''')\n",
    "  print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  total_loss_test = 0\n",
    "  total_acc_test = 0\n",
    "  \n",
    "  for data in test_dataloader:\n",
    "    inputs, labels = data\n",
    "    prediction = model(inputs).squeeze(1)\n",
    "    batch_loss_test = criterion(prediction,labels).item()\n",
    "    total_loss_test += batch_loss_test\n",
    "    \n",
    "    acc = ((prediction).round() == labels).sum().item()\n",
    "    total_acc_test += acc\n",
    "    \n",
    "print(\"Testing accuracy: \",round(total_acc_train/(testing_data.__len__())*100, 4)//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "axs[0].plot(total_loss_train_plot, label='Training Loss')\n",
    "axs[0].plot(total_loss_validation_plot, label='Validation Loss')\n",
    "axs[0].set_title('Training and Validation Loss over Epochs')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].set_ylim([0, 2])\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(total_acc_train_plot, label='Training Accuracy')\n",
    "axs[1].plot(total_acc_validation_plot, label='Validation Accuracy')\n",
    "axs[1].set_title('Training and Validation Accuracy over Epochs')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_ylim([0, 100])\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 2357/organized['Area'].abs().max()\n",
    "MajorAxisLength = 81/organized['MajorAxisLength'].abs().max()\n",
    "MinorAxisLength = 42/organized['MinorAxisLength'].abs().max()\n",
    "Eccentricity = 32/organized['Eccentricity'].abs().max()\n",
    "ConvexArea = 12/organized['ConvexArea'].abs().max()\n",
    "EquivDiameter = 33/organized['EquivDiameter'].abs().max()\n",
    "Extent = 98/organized['Extent'].abs().max()\n",
    "Perimeter = 927/organized['Perimeter'].abs().max()\n",
    "Roundness = 677/organized['Roundness'].abs().max()\n",
    "AspectRation = 24/organized['AspectRation'].abs().max()\n",
    "Class = 24/organized['Class'].abs().max()\n",
    "\n",
    "my_inputs = [area, MajorAxisLength, MinorAxisLength, Eccentricity, ConvexArea, EquivDiameter, Extent, Perimeter, Roundness, AspectRation]\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "# Check the expected feature count\n",
    "expected_features = X.shape[1]\n",
    "\n",
    "# If missing a feature, manually add a placeholder (e.g., 0.0 or mean value)\n",
    "if len(my_inputs) < expected_features:\n",
    "    my_inputs.append(0.0)  # Adjust based on your dataset logic\n",
    "\n",
    "# Convert to tensor\n",
    "my_inputs = torch.tensor(my_inputs, dtype=torch.float32).reshape(1, expected_features).to(device)\n",
    "\n",
    "# Now pass to the model\n",
    "prediction = model(my_inputs)\n",
    "print(prediction)\n",
    "print(\"Class is:\", round(prediction.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
